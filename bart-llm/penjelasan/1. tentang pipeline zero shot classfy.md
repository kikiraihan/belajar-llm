Oke, mari kita kupas satu per satu ðŸš€

## ðŸ”Ž Apa itu **Zero-Shot Classification**

**Zero-shot classification** adalah teknik NLP (Natural Language Processing) di mana sebuah model bisa melakukan klasifikasi teks **tanpa pernah dilatih secara khusus pada label yang digunakan**.

Contoh:
Biasanya, kalau bikin model klasifikasi, kita harus punya dataset dengan label tertentu (misalnya: *"spam"* vs *"not spam"*).
Tapi dengan **zero-shot**, kita bisa langsung kasih teks + daftar label apa saja yang kita inginkan (*custom labels*), lalu model akan "menalar" hubungan teks dengan label menggunakan *natural language inference (NLI)*.

---

## ðŸ› ï¸ Bagaimana cara kerjanya di belakang pipeline `transformers`

Ketika kamu panggil:

```python
classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
```

Yang terjadi di belakang layar adalah:

1. **Pipeline Setup**
   Hugging Face `pipeline` membungkus model NLP supaya mudah dipakai tanpa harus paham detail preprocessing â†’ inference â†’ postprocessing.

2. **Model yang dipakai (misalnya BART MNLI)**

   * Model BART ini awalnya dilatih untuk **NLI (Natural Language Inference)**.
   * NLI berarti: diberi dua kalimat, model menentukan apakah:

     * **Entailment** (kalimat pertama mendukung kalimat kedua),
     * **Contradiction** (bertentangan),
     * **Neutral** (tidak ada hubungan).

   Contoh NLI:

   * Premise: *"The man is playing guitar."*
   * Hypothesis: *"A person is making music."*
   * Label: **Entailment** âœ…

3. **Bagaimana dikaitkan ke Zero-Shot Classification**

   * Teks input dianggap sebagai **premise**.
   * Setiap kandidat label diubah menjadi kalimat hipotesis dengan template seperti:

     > "This text is about {label}."
   * Lalu model NLI mengevaluasi apakah input *meng-entail* hipotesis tersebut.
   * Skor entailment itulah yang dipakai sebagai probabilitas label.

   Misalnya input: `"Halo, apa kabar?"`
   Kandidat label: `["Chit Chat", "Fact Question", "Hacking LLM"]`

   * Model cek:

     * Apakah teks ini â†’ "This text is about Chit Chat"?
     * Apakah teks ini â†’ "This text is about Fact Question"?
     * Apakah teks ini â†’ "This text is about Hacking LLM"?
   * Hasil skor dibandingkan â†’ label dengan skor tertinggi dipilih.

4. **Output**
   Pipeline akhirnya memberi dictionary seperti ini:

   ```python
   {
     'sequence': "Halo, apa kabar?",
     'labels': ['Chit Chat', 'Fact Question', 'Hacking LLM'],
     'scores': [0.95, 0.03, 0.02]
   }
   ```

   Jadi meskipun model **tidak pernah dilatih khusus** untuk label â€œChit Chatâ€ atau â€œHacking LLMâ€, dia tetap bisa *menebak* karena dilatih di tugas *entailment*.

---

## ðŸ“Š Visualisasi Alur di Belakangnya

```
[Input Teks] ---> [Premise]

[Labels] ---> [Generate Hypotheses: "This text is about {label}"]

(Premise, Hypothesis) ---> [NLI Model] ---> [Entailment Scores] ---> [Ranking Label]
```

---

ðŸ‘‰ Jadi, **zero-shot classification** memanfaatkan kemampuan *reasoning* dari model NLI (seperti BART MNLI atau RoBERTa MNLI) untuk *mengeneralisasi* ke label-label yang tidak ada di dataset latihnya.

---

Mau saya bikinkan **diagram sederhana (flowchart)** supaya lebih gampang dipahami alurnya?
